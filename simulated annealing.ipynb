{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "559f5996",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"탐색을 통한 문제 해결을 위해 필요한 기반 구조들.\n",
    "GitHub의 aima-python 코드를 기반으로 일부 내용을 수정하였음.\"\"\"\n",
    "import math\n",
    "import heapq\n",
    "import sys\n",
    "from collections import defaultdict, deque\n",
    "\n",
    "\n",
    "class Problem:\n",
    "    \"\"\"해결할 문제에 대한 추상 클래스\n",
    "    다음 절차에 따라 이 클래스를 활용하여 문제해결하면 됨.\n",
    "    1. 이 클래스의 서브클래스 생성 (이 서브클래스를 편의상 YourProblem이라고 하자)\n",
    "    2. 다음 메쏘드들 구현\n",
    "       - actions\n",
    "       - result\n",
    "       - 필요에 따라 h, __init__, is_goal, action_cost도\n",
    "    3. YourProblem의 인스턴스를 생성\n",
    "    4. 다양한 탐색 함수들을 사용해서 YourProblem을 해결\"\"\"\n",
    "\n",
    "    def __init__(self, initial=None, goal=None, **kwds): #Problem 클래스의 생성자 \n",
    "        # **가변 키워드 인자 : 임의의 키워드 인자를 받을 수 있도록 한다. \n",
    "        # =None 매개변수를 지정하지 않았을 경우, none 으로 초기화한다.\n",
    "        \"\"\"초기 상태(initial), 목표 상태(goal) 지정.\n",
    "        필요에 따라 다른 파라미터들 추가\"\"\"\n",
    "        self.__dict__.update(initial=initial, goal=goal, **kwds)  \n",
    "        # __dict__: 객체의 '속성' 정보를 담고 있는 딕셔너리\n",
    "        # 클래스의 속성 정보를 저장하는 코드\n",
    "\n",
    "    def actions(self, state):\n",
    "        \"\"\"행동: 주어진 상태(state)에서 취할 수 있는 행동들을 리턴함.\n",
    "        대개 리스트 형태로 리턴하면 될 것임.\n",
    "        한꺼번에 리턴하기에 너무 많은 행동들이 있을 경우, yield 사용을 검토할 것.\"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def result(self, state, action):\n",
    "        \"\"\"이행모델: 주어진 상태(state)에서 주어진 행동(action)을 취했을 때의 결과 상태를 리턴함.\n",
    "        action은 self.actions(state) 중 하나여야 함.\"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def is_goal(self, state):\n",
    "        \"\"\"목표검사: 상태가 목표 상태이면 True를 리턴함.\n",
    "        상태가 self.goal과 일치하는지 혹은 self.goal이 리스트인 경우 그 중의 하나인지 체크함.\n",
    "        더 복잡한 목표검사가 필요할 경우 이 메쏘드를 오버라이드하면 됨.\"\"\"\n",
    "        if isinstance(self.goal, list):\n",
    "            return is_in(state, self.goal)\n",
    "        else:\n",
    "            return state == self.goal\n",
    "\n",
    "    def action_cost(self, state1, action, state2):\n",
    "        \"\"\"행동 비용: state1에서 action을 통해 state2에 이르는 비용을 리턴함.\n",
    "        경로가 중요치 않은 문제의 경우에는 state2만을 고려한 함수가 될 것임.\n",
    "        현재 구현된 기본 버전은 모든 상태에서 행동 비용을 1로 산정함.\"\"\"\n",
    "        return 1\n",
    "\n",
    "    def h(self, node):\n",
    "        \"\"\"휴리스틱 함수:\n",
    "        문제에 따라 휴리스틱 함수를 적절히 변경해줘야 함.\"\"\"\n",
    "        return 0\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f'{type(self).__name__}({self.initial!r}, {self.goal!r})'\n",
    "\n",
    "    \n",
    "def is_in(elt, seq):\n",
    "    \"\"\"elt가 seq의 원소인지 체크.\n",
    "    (elt in seq)와 유사하나 ==(값의 비교)이 아닌 is(객체의 일치 여부)로 비교함.\"\"\"\n",
    "    return any(x is elt for x in seq)\n",
    "\n",
    "\n",
    "class Node:\n",
    "    \"\"\"탐색 트리의 노드. 다음 요소들로 구성됨.\n",
    "    - 이 노드에 대응되는 상태(한 상태에 여러 노드가 대응될 수도 있음)\n",
    "    - 이 노드를 생성한 부모에 대한 포인터\n",
    "    - 이 상태에 이르게 한 행동\n",
    "    - 경로 비용(g)\n",
    "    이 클래스의 서브클래스를 만들 필요는 없을 것임.\"\"\"\n",
    "\n",
    "    def __init__(self, state, parent=None, action=None, path_cost=0):\n",
    "        \"\"\"parent에서 action을 취해 만들어지는 탐색 트리의 노드 생성\"\"\"\n",
    "        self.__dict__.update(state=state, parent=parent, action=action, path_cost=path_cost)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"<{self.state}>\"\n",
    "\n",
    "    def __len__(self): # 탐색 트리에서 이 노드의 깊이\n",
    "        return 0 if self.parent is None else (1 + len(self.parent))\n",
    "    \n",
    "    def __lt__(self, other):\n",
    "        return self.path_cost < other.path_cost\n",
    "        \n",
    "        \n",
    "failure = Node('failure', path_cost=math.inf) # 알고리즘이 해결책을 찾을 수 없음을 나타냄\n",
    "cutoff  = Node('cutoff',  path_cost=math.inf) # 반복적 깊이 증가 탐색이 중단(cut off)됐음을 나타냄\n",
    "\n",
    "\n",
    "def expand(problem, node): \n",
    "    \"\"\"노드 확장: 이 노드에서 한 번의 움직임으로 도달 가능한 자식 노드들을 생성하여 yield함\"\"\"\n",
    "    s = node.state #현재 상태\n",
    "    for action in problem.actions(s):\n",
    "        s1 = problem.result(s, action) #상태의 전이모델 result()의 반환값\n",
    "        cost = node.path_cost + problem.action_cost(s, action, s1)\n",
    "        yield Node(s1, node, action, cost) #새로운 Node 객체를 생성하여 반환하는 역할\n",
    "        \n",
    "\n",
    "def path_actions(node):\n",
    "    \"\"\"루트 노드에서부터 이 노드까지 이르는 행동 시퀀스. \n",
    "    결국 node가 목표 상태라면 이 행동 시퀀스는 해결책임.\n",
    "    목표 상태 발견 후 리턴할 행동 시퀀스 생성을 위해 사용됨.\n",
    "    부모 포인터를 역으로 추적하여 시퀀스 생성\"\"\"\n",
    "    if node.parent is None:\n",
    "        return []  \n",
    "    return path_actions(node.parent) + [node.action]\n",
    "\n",
    "\n",
    "def path_states(node):\n",
    "    \"\"\"루트 노드에서부터 이 노드까지 이르는 상태 시퀀스\"\"\"\n",
    "    if node in (cutoff, failure, None): \n",
    "        return []\n",
    "    return path_states(node.parent) + [node.state]\n",
    "\n",
    "\n",
    "# FIFO Queue\n",
    "FIFOQueue = deque\n",
    "\n",
    "# LIFO Queue(Stack)\n",
    "LIFOQueue = list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "068d7e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 탐색을 통한 문제 해결을 위해 필요한 기반 구조들은 search_common.py에 코드를 옮겨서 저장해뒀음.\n",
    "from search_common import *\n",
    "import operator\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt  # 시각화 모듈\n",
    "from PIL import Image\n",
    "import bisect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32cc0de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#simulated annealing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9107aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exp_schedule(k=20, lam=0.005, limit=10000): \n",
    "    ## k: 초기 온도를 결정하는 상수. lam: 시간에 따른 온도의 감소율을 결정하는 상수. limit:온도가 0이 될 때까지의 시간(또는 반복 횟수)의 한계\n",
    "    \"\"\"simulated annealing용 schedule 함수\"\"\"\n",
    "    return lambda t: (k * np.exp(-lam * t) if t < limit else 0) \n",
    "    #t가 limit보다 작은 경우에는 초기 온도 k에 지수함수 형태로 감소하는 값을 반환하고, 그렇지 않으면 0을 반환\n",
    "\n",
    "\n",
    "def simulated_annealing(problem, schedule=exp_schedule()):\n",
    "    \"\"\"simulated annealing\"\"\"\n",
    "    current = Node(problem.initial) #노드 객체 생성\n",
    "    for t in range(sys.maxsize): #0~maxsize 까지 1씩 증가하며 반복\n",
    "        T = schedule(t)\n",
    "        \n",
    "        if T == 0:\n",
    "            return current.state\n",
    "        \n",
    "        neighbors = [n for n in expand(problem, current)]\n",
    "        \n",
    "        if len(neighbors) == 0:\n",
    "            return current.state\n",
    "        \n",
    "        next_choice = random.choice(neighbors) #이웃하는 노드 중에서 무작위 추출\n",
    "        delta_e = problem.value(next_choice.state) - problem.value(current.state)\n",
    "        if delta_e > 0 or probability(np.exp(delta_e / T)): #다음상태-현재상태 >0 ==> 다음상태가 더 커지는 방향으로 가겠다\n",
    "            current = next_choice #다음 상태로 현재 상태를 이동\n",
    "\n",
    "            \n",
    "def probability(p):\n",
    "    \"\"\"p의 확률로 True를 리턴함.\"\"\"\n",
    "    return p > random.uniform(0.0, 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e2fa36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 미리 정의된 행동들\n",
    "directions4 = [(-1, 0), (0, 1), (1, 0), (0, -1)] # 상우하좌 4 방향 (4방향으로만 행동을 허용하도록 문제를 정의할 경우 사용) 배열로 생각하기\n",
    "directions8 = directions4 + [(-1, 1), (1, 1), (1, -1), (-1, -1)] # 대각선 4 방향 추가 (대각선 방향 행동도 허용하여 문제 정의할 경우 사용)\n",
    "\n",
    "class PeakFindingProblem(Problem):\n",
    "    \"\"\"봉우리 찾기 문제. 상태는 현재의 위치. 예: (1, 2)\"\"\"\n",
    "\n",
    "    def __init__(self, initial, grid, defined_actions=directions4):\n",
    "        \"\"\"grid: 2차원 배열/리스트. grid의 각 상태는 위치 인덱스 튜플 (x, y)로 표현됨.\n",
    "        defined_actions: 문제에서 허용할 행동 정의(기본값: 4방향 이동 행동)\"\"\"\n",
    "        super().__init__(initial) #에이전트의 시작 위치\n",
    "        self.grid = grid #상태 공간\n",
    "        self.defined_actions = defined_actions #4방향 이동 가능하다는 행동\n",
    "        \n",
    "        self.n = len(grid)  # 행 인덱스(x)의 최대값 , 3\n",
    "        assert self.n > 0 #주어진 조건식이 거짓이면 AssertionError\n",
    "        self.m = len(grid[0])  # 열 인덱스(y)의 최대값 , 4; 결국 이 그리드의 크기는 n행 m열, 3행 4열\n",
    "        assert self.m > 0\n",
    "\n",
    "    def actions(self, state): #행동들의 집합, state에서 가능한 행동 리스트(=배열) 반환\n",
    "        \"\"\"주어진 상태에서 허용되는 행동 리스트\"\"\"\n",
    "        allowed_actions = []\n",
    "        for action in self.defined_actions: #[(-1, 0), (0, 1), (1, 0), (0, -1)]\n",
    "            \n",
    "            next_state = vector_add(state, action) #state(1,2 현위치) + action(-1,0 왼쪽으로 이동) = (0,2)\n",
    "            \n",
    "            if 0 <= next_state[0] <= self.n - 1 and 0 <= next_state[1] <= self.m - 1:\n",
    "                #행이 0~2 사이이고, 열이 0~3 사이인지 확인\n",
    "                \n",
    "                allowed_actions.append(action) #가능한 행동이므로 추가\n",
    "                \n",
    "        return allowed_actions\n",
    "\n",
    "    def result(self, state, action): #state에서 action(배열)의 결과 'state', 전이모델 #expand()에서 상태로 사용\n",
    "        \"\"\"행동에 명시된 방향으로 이동\"\"\"\n",
    "        return vector_add(state, action) # 두백터의 합을 반환\n",
    "\n",
    "    def value(self, state): #상태 --> 여기서는 배열의 x,y인덱스에 저장된 실제 값을 반환 / 우리는 경로의 거리의 전체 합을 반환해야함\n",
    "        \"\"\"상태 값: 이 문제에서는 그 위치에 놓인 숫자 값을 리턴함\"\"\"\n",
    "        x, y = state #튜플의 값을 대입 x,y=(1,2)\n",
    "        assert 0 <= x < self.n\n",
    "        assert 0 <= y < self.m\n",
    "        return self.grid[x][y]\n",
    "\n",
    "\n",
    "def vector_add(a, b):\n",
    "    \"\"\"두 벡터의 각 성분별로 덧셈 연산\"\"\"\n",
    "    return tuple(map(operator.add, a, b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7be0a80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 숫자들의 배치\n",
    "grid = [[3, 7, 2, 8], [5, 2, 9, 1], [5, 3, 3, 1]] #상태 공간\n",
    "\n",
    "initial = (0, 0)\n",
    "problem = PeakFindingProblem(initial, grid, directions4) #초기상태, 상태공간, 가능한 행동의 집합을 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d35caeac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 1)\t7\n"
     ]
    }
   ],
   "source": [
    "final = simulated_annealing(problem) #알고리즘 시작\n",
    "print(final, problem.value(final), sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e4353180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{8, 9, 5, 7}\t9\n"
     ]
    }
   ],
   "source": [
    "# 여러번 반복해서 해를 찾고 그 결과 중 최대값을 리턴하면 최적해일 가능성이 높아질 것임\n",
    "solutions = {problem.value(simulated_annealing(problem)) for i in range(100)}\n",
    "print(solutions, max(solutions), sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "87b54a91",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "print(len(grid))\n",
    "print(len(grid[0])) #[3,7,2,8]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
